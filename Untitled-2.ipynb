{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (48351, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# //\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset with low_memory=False to avoid dtype warnings\n",
    "df = pd.read_csv(\"vehicles.csv\", low_memory=False)\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = ['make', 'model', 'year', 'cylinders', 'displ', 'fuelType', 'VClass', 'comb08']\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# Rename target variable (MPG)\n",
    "df_selected.rename(columns={'comb08': 'mpg'}, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df_selected = df_selected.dropna(subset=['mpg'])  # Drop rows where mpg is missing\n",
    "df_selected['cylinders'] = df_selected['cylinders'].fillna(df_selected['cylinders'].median())\n",
    "df_selected['displ'] = df_selected['displ'].fillna(df_selected['displ'].median())\n",
    "\n",
    "# Limit categories for 'make' and 'model' to the top 30 most frequent values\n",
    "top_makes = df_selected['make'].value_counts().index[:30]\n",
    "top_models = df_selected['model'].value_counts().index[:30]\n",
    "\n",
    "df_selected['make'] = df_selected['make'].apply(lambda x: x if x in top_makes else 'Other')\n",
    "df_selected['model'] = df_selected['model'].apply(lambda x: x if x in top_models else 'Other')\n",
    "\n",
    "# Label Encoding for categorical variables\n",
    "label_encoders = {}\n",
    "for col in ['make', 'model', 'fuelType', 'VClass']:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[col] = le.fit_transform(df_selected[col])\n",
    "    label_encoders[col] = le  # Store encoders for future use\n",
    "\n",
    "# Standardizing 'displ' feature\n",
    "scaler = StandardScaler()\n",
    "df_selected[['displ']] = scaler.fit_transform(df_selected[['displ']])\n",
    "\n",
    "# Display final dataset shape\n",
    "print(\"Final dataset shape:\", df_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Completed. Final dataset shape: (48351, 8)\n"
     ]
    }
   ],
   "source": [
    "# //\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset with low_memory=False to avoid dtype warnings\n",
    "df = pd.read_csv(\"vehicles.csv\", low_memory=False)\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = ['make', 'model', 'year', 'cylinders', 'displ', 'fuelType', 'VClass', 'comb08']\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# Rename target variable (MPG)\n",
    "df_selected.rename(columns={'comb08': 'mpg'}, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df_selected = df_selected.dropna(subset=['mpg'])  # Drop rows where mpg is missing\n",
    "df_selected['cylinders'] = df_selected['cylinders'].fillna(df_selected['cylinders'].median())\n",
    "df_selected['displ'] = df_selected['displ'].fillna(df_selected['displ'].median())\n",
    "\n",
    "# Label Encoding for categorical variables\n",
    "label_encoders = {}\n",
    "for col in ['make', 'model', 'fuelType', 'VClass']:\n",
    "    le = LabelEncoder()\n",
    "    df_selected[col] = le.fit_transform(df_selected[col])\n",
    "    label_encoders[col] = le  # Store encoders for future use\n",
    "\n",
    "# Standardizing 'displ' feature\n",
    "scaler = StandardScaler()\n",
    "df_selected[['displ']] = scaler.fit_transform(df_selected[['displ']])\n",
    "\n",
    "# Save the preprocessed data to a new CSV file\n",
    "df_selected.to_csv(\"vehicles_preprocessed1.csv\", index=False)\n",
    "\n",
    "# Display final dataset shape\n",
    "print(\"Preprocessing Completed. Final dataset shape:\", df_selected.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48351 entries, 0 to 48350\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   make       48351 non-null  int64  \n",
      " 1   model      48351 non-null  int64  \n",
      " 2   year       48351 non-null  int64  \n",
      " 3   cylinders  48351 non-null  float64\n",
      " 4   displ      48351 non-null  float64\n",
      " 5   fuelType   48351 non-null  int64  \n",
      " 6   VClass     48351 non-null  int64  \n",
      " 7   mpg        48351 non-null  int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 3.0 MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "               make         model          year     cylinders         displ  \\\n",
      "count  48351.000000  48351.000000  48351.000000  48351.000000  4.835100e+04   \n",
      "mean      64.667970   2581.629584   2004.655912      5.705156  3.879615e-17   \n",
      "std       40.386345   1479.326215     12.711662      1.753441  1.000010e+00   \n",
      "min        0.000000      0.000000   1984.000000      2.000000 -2.439109e+00   \n",
      "25%       32.000000   1343.000000   1993.000000      4.000000 -7.951770e-01   \n",
      "50%       55.000000   2470.000000   2006.000000      6.000000 -1.973836e-01   \n",
      "75%       92.000000   3959.000000   2016.000000      6.000000  6.245822e-01   \n",
      "max      144.000000   5250.000000   2025.000000     16.000000  3.837721e+00   \n",
      "\n",
      "           fuelType        VClass           mpg  \n",
      "count  48351.000000  48351.000000  48351.000000  \n",
      "mean       9.961966     14.270398     22.242063  \n",
      "std        2.965423     11.223521     12.298466  \n",
      "min        0.000000      0.000000      7.000000  \n",
      "25%        8.000000      2.000000     17.000000  \n",
      "50%       12.000000     13.000000     20.000000  \n",
      "75%       12.000000     26.000000     24.000000  \n",
      "max       14.000000     33.000000    146.000000  \n",
      "\n",
      "Correlation Matrix:\n",
      "               make     model      year  cylinders     displ  fuelType  \\\n",
      "make       1.000000  0.035349  0.000534  -0.252170 -0.267640  0.051467   \n",
      "model      0.035349  1.000000  0.035176   0.008159  0.025794  0.024533   \n",
      "year       0.000534  0.035176  1.000000   0.039863 -0.015395 -0.288661   \n",
      "cylinders -0.252170  0.008159  0.039863   1.000000  0.904066 -0.232132   \n",
      "displ     -0.267640  0.025794 -0.015395   0.904066  1.000000 -0.177978   \n",
      "fuelType   0.051467  0.024533 -0.288661  -0.232132 -0.177978  1.000000   \n",
      "VClass    -0.119020  0.098799 -0.066414   0.203405  0.251147 -0.017372   \n",
      "mpg        0.143113  0.027558  0.293621  -0.281164 -0.347749 -0.328442   \n",
      "\n",
      "             VClass       mpg  \n",
      "make      -0.119020  0.143113  \n",
      "model      0.098799  0.027558  \n",
      "year      -0.066414  0.293621  \n",
      "cylinders  0.203405 -0.281164  \n",
      "displ      0.251147 -0.347749  \n",
      "fuelType  -0.017372 -0.328442  \n",
      "VClass     1.000000 -0.153308  \n",
      "mpg       -0.153308  1.000000  \n",
      "\n",
      "Number of Outliers in MPG: 1995\n",
      "Outlier Data Sample:\n",
      "     make  model  year  cylinders     displ  fuelType  VClass  mpg\n",
      "776    25   4390  1994        3.0 -1.691867        12      28   41\n",
      "823    46   3034  1994        3.0 -1.691867        12      28   40\n",
      "825    46   3037  1994        3.0 -1.691867        12      28   47\n",
      "827    50   1392  1994        4.0 -1.318246        12      28   38\n",
      "828    50   1392  1994        4.0 -1.318246        12      28   36\n",
      "\n",
      "Unique values count in 'make': 145\n",
      "\n",
      "Unique values count in 'model': 5251\n",
      "\n",
      "Unique values count in 'fuelType': 15\n",
      "\n",
      "Unique values count in 'VClass': 34\n",
      "\n",
      "MPG Distribution across Bins:\n",
      "mpg\n",
      "(6.861, 20.9]     25840\n",
      "(20.9, 34.8]      20516\n",
      "(34.8, 48.7]        810\n",
      "(48.7, 62.6]        158\n",
      "(62.6, 76.5]        176\n",
      "(76.5, 90.4]        291\n",
      "(90.4, 104.3]       254\n",
      "(104.3, 118.2]      203\n",
      "(118.2, 132.1]       82\n",
      "(132.1, 146.0]       21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# //\n",
    "import pandas as pd\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df = pd.read_csv(\"vehicles_preprocessed.csv\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Correlation Matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(df.corr())\n",
    "\n",
    "# Identify Outliers using IQR Method\n",
    "Q1 = df['mpg'].quantile(0.25)\n",
    "Q3 = df['mpg'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['mpg'] < lower_bound) | (df['mpg'] > upper_bound)]\n",
    "print(f\"\\nNumber of Outliers in MPG: {outliers.shape[0]}\")\n",
    "print(\"Outlier Data Sample:\")\n",
    "print(outliers.head())\n",
    "\n",
    "# Count of Unique Values in Categorical Features\n",
    "categorical_features = ['make', 'model', 'fuelType', 'VClass']\n",
    "for col in categorical_features:\n",
    "    print(f\"\\nUnique values count in '{col}': {df[col].nunique()}\")\n",
    "\n",
    "# Distribution Analysis of MPG (Bin Count)\n",
    "mpg_bins = pd.cut(df['mpg'], bins=10).value_counts().sort_index()\n",
    "print(\"\\nMPG Distribution across Bins:\")\n",
    "print(mpg_bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Iteration 1 🔄\n",
      "\n",
      "🔄 Iteration 2 🔄\n",
      "\n",
      "🔄 Iteration 3 🔄\n",
      "📊 Final Model Performance:\n",
      "MAE: 0.9303485945197232\n",
      "MSE: 2.701677999970396\n",
      "R² Score: 0.9800921402642504\n",
      "K-Fold R² Scores: [0.99482591 0.99275316 0.99436983 0.99263992 0.99441663]\n",
      "Mean R² Score: 0.9938010886650849\n"
     ]
    }
   ],
   "source": [
    "# //\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset (replace 'your_data.csv' with your actual dataset)\n",
    "df = pd.read_csv(\"vehicles_preprocessed.csv\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=[\"mpg\"])  # Assuming 'mpg' is the target variable\n",
    "y = df[\"mpg\"]\n",
    "\n",
    "# Train-Test Split (80% Train, 20% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "lr = LinearRegression()\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Hybrid Model Iteration (Loop)\n",
    "num_iterations = 3\n",
    "for i in range(num_iterations):\n",
    "    print(f\"\\n🔄 Iteration {i+1} 🔄\")\n",
    "    \n",
    "    # Step 1: Train Linear Regression & Predict\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_lr_train = lr.predict(X_train)\n",
    "    y_pred_lr_test = lr.predict(X_test)\n",
    "\n",
    "    # Step 2: Use Linear Regression predictions as a feature for Random Forest\n",
    "    X_train_rf = np.column_stack((X_train, y_pred_lr_train))\n",
    "    X_test_rf = np.column_stack((X_test, y_pred_lr_test))\n",
    "\n",
    "    # Step 3: Train Random Forest\n",
    "    rf.fit(X_train_rf, y_train)\n",
    "    y_pred_rf_train = rf.predict(X_train_rf)\n",
    "    y_pred_rf_test = rf.predict(X_test_rf)\n",
    "\n",
    "    # Step 4: Use Random Forest predictions as a feature for Linear Regression (loop back)\n",
    "    X_train = np.column_stack((X_train, y_pred_rf_train))\n",
    "    X_test = np.column_stack((X_test, y_pred_rf_test))\n",
    "\n",
    "# Final Predictions\n",
    "final_preds = y_pred_rf_test\n",
    "\n",
    "# Model Evaluation\n",
    "mae = mean_absolute_error(y_test, final_preds)\n",
    "mse = mean_squared_error(y_test, final_preds)\n",
    "r2 = r2_score(y_test, final_preds)\n",
    "\n",
    "print(f\"📊 Final Model Performance:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(rf, X_train_rf, y_train, cv=kf, scoring=\"r2\")\n",
    "print(f\"K-Fold R² Scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score: {cv_scores.mean()}\")\n",
    "\n",
    "# # Hyperparameter Tuning (Grid Search)\n",
    "# param_grid = {\n",
    "#     \"n_estimators\": [100, 200, 300],\n",
    "#     \"max_depth\": [None, 10, 20],\n",
    "#     \"min_samples_split\": [2, 5, 10],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "# grid_search.fit(X_train_rf, y_train)\n",
    "# best_rf = grid_search.best_estimator_\n",
    "\n",
    "# print(f\"✅ Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# # # Save the model for Streamlit Deployment\n",
    "# # joblib.dump(best_rf, \"hybrid_mileage_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage: 89.6%\n"
     ]
    }
   ],
   "source": [
    "# //\n",
    "\n",
    "import psutil\n",
    "print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomisedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "✅ Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "# //\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    param_distributions=param_grid, \n",
    "    cv=3,  # Reduce folds from 5 to 3 to speed up\n",
    "    scoring=\"r2\", \n",
    "    n_jobs=-1,\n",
    "    n_iter=10,  # Try only 10 random combinations instead of all 27\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_rf, y_train)\n",
    "best_rf = random_search.best_estimator_\n",
    "print(f\"✅ Best Parameters: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# //\n",
    "# Hyperparameter Tuning (Grid Search)\n",
    "\n",
    "import gc\n",
    "\n",
    "# # Free up memory before GridSearch\n",
    "# del X_train, X_test, y_test\n",
    "# gc.collect()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [5, 7, 10],\n",
    "    \"min_samples_split\": [10, 15],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "grid_search.fit(X_train_rf, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "print(f\"✅ Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare predictions with actual values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "y_pred = best_rf.predict(X_test_rf)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "comparison_df = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred})\n",
    "print(comparison_df.head(10))  # Show first 10 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate error metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"📊 Model Performance Metrics:\")\n",
    "print(f\"✅ Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"✅ Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"✅ Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"✅ R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize prdicitons vs actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color=\"blue\", alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")  # 45-degree reference line\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, color=\"purple\", alpha=0.6)\n",
    "plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = best_rf.score(X_train_rf, y_train)\n",
    "test_r2 = best_rf.score(X_test_rf, y_test)\n",
    "\n",
    "print(f\"Train R² Score: {train_r2:.4f}\")\n",
    "print(f\"Test R² Score: {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_test = best_rf.predict(X_test_rf)\n",
    "\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "plt.xlabel(\"Actual MPG\")\n",
    "plt.ylabel(\"Predicted MPG\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color=\"red\", linestyle=\"--\")  # Perfect Fit Line\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "residuals = y_test - y_pred_test\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.xlabel(\"Residuals (Errors)\")\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimized RandomForestRegressor model for final predictions\n",
    "final_preds = best_rf.predict(X_test_rf)\n",
    "\n",
    "# Model Evaluation\n",
    "mae = mean_absolute_error(y_test, final_preds)\n",
    "mse = mean_squared_error(y_test, final_preds)\n",
    "r2 = r2_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\n📊 Final Optimized Model Performance:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"Feature {i}\" for i in range(X_train_rf.shape[1])]\n",
    "feature_importance = pd.Series(best_rf.feature_importances_, index=feature_names)\n",
    "feature_importance.sort_values(ascending=False).plot(kind=\"bar\", figsize=(10,5), title=\"Feature Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(best_rf, X_train_rf)\n",
    "shap_values = explainer(X_test_rf)\n",
    "shap.summary_plot(shap_values, X_test_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
